{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../Feature-eng/test.csv', index_col=None)\n",
    "X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "feature_names = X_test.columns\n",
    "feature_types = X_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mult = pd.read_csv('../Feature-eng/train-new.csv', index_col=False)\n",
    "# X, y = mult.iloc[:, 1:], mult.iloc[:, 0]\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "#                                                     test_size=0.2, \n",
    "#                                                     random_state=123,\n",
    "#                                                     stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtrain = xgb.DMatrix(data=X_train.values, label=y_train.values)\n",
    "# dtest = xgb.DMatrix(data=X_test.values, label=y_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:12:36] 964501x169 matrix with 163000669 entries loaded from ../Feature-eng/train.csv?format=csv&label_column=0\n",
      "169\n"
     ]
    }
   ],
   "source": [
    "# read in data\n",
    "dtrain = xgb.DMatrix('../Feature-eng/train.csv?format=csv&label_column=0')\n",
    "# dtest = xgb.DMatrix(data=X_test.values, label=y_test.values)\n",
    "dtest = xgb.DMatrix(data=X_test.values, label=y_test.values)\n",
    "# specify parameters via map\n",
    "# make prediction\n",
    "print(dtrain.num_col())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'max_depth': 10, 'eta': 0.3, 'silent': 1, 'objective': 'binary:logistic', \n",
    "         'min_child_weight': 3.781067239275553, 'colsample_bytree': 0.9149522148929845, \n",
    "         'gamma': 1.4399646786455722, 'subsample': 0.9171271673354395\n",
    "        }\n",
    "\n",
    "param['eval_metric'] = ['auc', 'aucpr', 'error', 'logloss']\n",
    "evallist = [(dtrain, 'train'), (dtest, 'eval')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param = {'max_depth': 6, 'eta': 0.3, 'silent': 1, 'objective': 'multi:softmax', 'subsample': 0.8, 'num_class': 4}\n",
    "\n",
    "# param['eval_metric'] = ['merror', 'mlogloss']\n",
    "# evallist = [(dtrain, 'train'), (dtest, 'eval')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_round = 100\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = bst.predict(dtest)\n",
    "labels = dtest.get_label()\n",
    "y_pred = (preds > 0.5).astype(int)\n",
    "# print(labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import log_loss\n",
    "# from sklearn.metrics import classification_report\n",
    "# print(classification_report(labels, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(log_loss(labels, y_pred, normalize=True, eps=1e-15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# fig = plt.figure(figsize=(100,100))\n",
    "# axes = fig.add_axes(rect=[1,1,1,1])\n",
    "# xgb.plot_importance(bst, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(log_loss(labels, bst.predict(dtest), normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bst.dump_model('xgb-baseline.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_x = sorted(bst.get_fscore().items(), key=lambda kv: kv[1])\n",
    "print(sorted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names[27])\n",
    "print(feature_names[0])\n",
    "print(feature_names[6])\n",
    "print(feature_names[7])\n",
    "print(feature_names[13])\n",
    "print(feature_names[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

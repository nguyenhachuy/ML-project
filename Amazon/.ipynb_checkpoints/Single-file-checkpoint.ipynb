{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "import sagemaker\n",
    "from sagemaker.predictor import csv_serializer\n",
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request, random\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "from pandas.api.types import CategoricalDtype\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-west-2 region. You will use the 433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# Define IAM role\n",
    "role = get_execution_role()\n",
    "prefix = 'xgboost'\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 bucket created successfully\n"
     ]
    }
   ],
   "source": [
    "bucket_name = 'hcp-ml-project-tune' # <--- change this variable to a unique name for your bucket\n",
    "bucket = bucket_name\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the downloaded data into train/test/validation files\n",
    "FILE_TRAIN = 'train'\n",
    "FILE_VALIDATION = 'validation'\n",
    "FILE_TEST = 'test'\n",
    "columns = ['WILL_ATTACH_IN_60', 'weight', 'ORGANIZATION_ID', \n",
    "       'PLAN_TIER', 'BILLING_PLAN_ID', 'CC_FEE', 'ASP', 'INDUSTRY', 'ORGSIZE',\n",
    "       'BANK_CONNECTED', 'BANK_VERIFIED', 'CREATED', 'SCHEDULED', 'OMW',\n",
    "       'STARTED', 'IN_PROGRESS', 'ESTIMATED', 'INVOICED', 'TOTALPAYMENT_COUNT',\n",
    "       'TOTALPAYMENT_AMOUNT', 'ONLINE_BOOKINGS', 'CC_COUNT', 'CC_AMOUNT',\n",
    "       'INSTAPAY_AMOUNT', 'ACH_COUNT', 'CASH_COUNT', 'CASH_AMOUNT',\n",
    "       'CHECK_COUNT', 'CHECK_AMOUNT', 'OTHER_COUNT', 'DAYS_SINCE_ENROLLMENT',\n",
    "       'REASON_TO_ADOPT', 'STAGENAME_PRODUCT', 'CC_COUNT_ALL',\n",
    "       'AVG_TIME_TO_PAYMENT', 'COMMITMENTS_ALL', 'COMMITMENTS', 'CC_PERC',\n",
    "       'CASH_PERC', 'CHECK_PERC', 'OTHER_PERC', 'ACH_PERC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weight(row):\n",
    "    attach_label = row['WILL_ATTACH_IN_60']\n",
    "    cc_count = row['CC_COUNT']\n",
    "    if attach_label == 1 and cc_count > 0:\n",
    "        return 0.5\n",
    "    elif attach_label == 0 and cc_count <= 0:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def get_dataset():\n",
    "    try:\n",
    "        df = pd.read_csv('../cc_attach_project.csv',index_col=0)\n",
    "        print('Success: Data loaded into dataframe.')\n",
    "    except Exception as e:\n",
    "        print('Data load error: ',e)\n",
    "    \n",
    "    to_drop = ['ENROLLMENT_DATE', 'DATE']\n",
    "    df.drop(to_drop, inplace=True, axis=1)\n",
    "    # df['ENROLLMENT_DATE'] = pd.to_datetime(df['ENROLLMENT_DATE'])\n",
    "    # df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "    df['STAGENAME_PRODUCT'] = df['STAGENAME_PRODUCT'].fillna('not called')\n",
    "    df['INDUSTRY'] = df['INDUSTRY'].fillna('missing')\n",
    "    df['CASH_PERC'] = df['CASH_PERC'].fillna(0.0)  \n",
    "    df['CHECK_PERC'] = df['CHECK_PERC'].fillna(0.0)\n",
    "    df['OTHER_PERC'] = df['OTHER_PERC'].fillna(0.0)\n",
    "    df['ACH_PERC'] = df['ACH_PERC'].fillna(0.0)\n",
    "    df['CC_PERC'] = df['CC_PERC'].fillna(0.0)\n",
    "    # df['BILLING_PLAN_ID'] = df['BILLING_PLAN_ID'].astype('int64')\n",
    "    cat_dtype = CategoricalDtype(categories=(df['PLAN_TIER'].unique()), ordered=True)\n",
    "    df['PLAN_TIER'] = df['PLAN_TIER'].astype(cat_dtype) #small > medium?\n",
    "    df['INDUSTRY'] = df['INDUSTRY'].astype('category')\n",
    "    df['ORGSIZE'] = df['ORGSIZE'].abs()\n",
    "    # df['ORGSIZE'].replace(0,1, inplace=True) #should I do this?\n",
    "\n",
    "    #convert to all floats\n",
    "    # df = df.apply(pd.to_numeric, errors='ignore', downcast='float')\n",
    "\n",
    "    #org_id same means same org!!!\n",
    "    weight = df.apply(assign_weight, axis=1)\n",
    "\n",
    "    df.insert(0, 'weight', weight, allow_duplicates=False) #insert weight into the df\n",
    "    df = df.reindex(columns, axis=\"columns\")\n",
    "    df = df.sample(frac=1, replace=False, random_state=1) #Shuffle the df\n",
    "\n",
    "    df = pd.get_dummies(df)\n",
    "    \n",
    "    print(df.shape)\n",
    "    train, test = train_test_split(df, test_size=0.15, random_state=123)\n",
    "    train, val = train_test_split(train, test_size=0.2, random_state=123)\n",
    "    \n",
    "    print(train.shape, test.shape, val.shape)\n",
    "    \n",
    "    return (train, test, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n",
      "(20000, 82)\n",
      "(13600, 82) (3000, 82) (3400, 82)\n",
      "       WILL_ATTACH_IN_60  weight  ORGANIZATION_ID  BILLING_PLAN_ID  CC_FEE  \\\n",
      "15427                  1     0.5             2061             58.0   0.029   \n",
      "17819                  0     1.0           116482             58.0   0.029   \n",
      "1959                   0     0.5            57941             58.0   0.029   \n",
      "7828                   0     0.5            56756             57.0   0.029   \n",
      "13534                  1     0.5            59965             59.0   0.029   \n",
      "\n",
      "         ASP  ORGSIZE  BANK_CONNECTED  BANK_VERIFIED  CREATED  \\\n",
      "15427  109.0        5               1              0      164   \n",
      "17819  137.0        2               1              1       30   \n",
      "1959   137.0        5               1              0       45   \n",
      "7828    49.0        2               1              0       11   \n",
      "13534  249.0       11               1              0      942   \n",
      "\n",
      "                   ...               INDUSTRY_Wildlife Control  \\\n",
      "15427              ...                                       0   \n",
      "17819              ...                                       0   \n",
      "1959               ...                                       0   \n",
      "7828               ...                                       0   \n",
      "13534              ...                                       0   \n",
      "\n",
      "       INDUSTRY_Window & Exterior Cleaning  INDUSTRY_Windows  \\\n",
      "15427                                    0                 0   \n",
      "17819                                    0                 0   \n",
      "1959                                     1                 0   \n",
      "7828                                     0                 0   \n",
      "13534                                    0                 0   \n",
      "\n",
      "       INDUSTRY_missing  STAGENAME_PRODUCT_Closed Lost_CC Attach:  \\\n",
      "15427                 0                                         0   \n",
      "17819                 0                                         0   \n",
      "1959                  0                                         0   \n",
      "7828                  0                                         0   \n",
      "13534                 0                                         0   \n",
      "\n",
      "       STAGENAME_PRODUCT_Closed Lost_Instapay Attach:  \\\n",
      "15427                                               0   \n",
      "17819                                               0   \n",
      "1959                                                0   \n",
      "7828                                                0   \n",
      "13534                                               0   \n",
      "\n",
      "       STAGENAME_PRODUCT_Coaching Attended_CC Usage: CC Attach: Instapay Attach:  \\\n",
      "15427                                                  0                           \n",
      "17819                                                  0                           \n",
      "1959                                                   0                           \n",
      "7828                                                   0                           \n",
      "13534                                                  0                           \n",
      "\n",
      "       STAGENAME_PRODUCT_Committed_CC Attach:  \\\n",
      "15427                                       0   \n",
      "17819                                       0   \n",
      "1959                                        0   \n",
      "7828                                        0   \n",
      "13534                                       0   \n",
      "\n",
      "       STAGENAME_PRODUCT_Committed_Instapay Attach:  \\\n",
      "15427                                             0   \n",
      "17819                                             0   \n",
      "1959                                              0   \n",
      "7828                                              0   \n",
      "13534                                             0   \n",
      "\n",
      "       STAGENAME_PRODUCT_not called  \n",
      "15427                             1  \n",
      "17819                             1  \n",
      "1959                              1  \n",
      "7828                              1  \n",
      "13534                             1  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "Index(['WILL_ATTACH_IN_60', 'weight', 'ORGANIZATION_ID', 'BILLING_PLAN_ID',\n",
      "       'CC_FEE', 'ASP', 'ORGSIZE', 'BANK_CONNECTED', 'BANK_VERIFIED',\n",
      "       'CREATED', 'SCHEDULED', 'OMW', 'STARTED', 'IN_PROGRESS', 'ESTIMATED',\n",
      "       'INVOICED', 'TOTALPAYMENT_COUNT', 'TOTALPAYMENT_AMOUNT',\n",
      "       'ONLINE_BOOKINGS', 'CC_COUNT', 'CC_AMOUNT', 'INSTAPAY_AMOUNT',\n",
      "       'ACH_COUNT', 'CASH_COUNT', 'CASH_AMOUNT', 'CHECK_COUNT', 'CHECK_AMOUNT',\n",
      "       'OTHER_COUNT', 'DAYS_SINCE_ENROLLMENT', 'REASON_TO_ADOPT',\n",
      "       'CC_COUNT_ALL', 'AVG_TIME_TO_PAYMENT', 'COMMITMENTS_ALL', 'COMMITMENTS',\n",
      "       'CC_PERC', 'CASH_PERC', 'CHECK_PERC', 'OTHER_PERC', 'ACH_PERC',\n",
      "       'PLAN_TIER_small', 'PLAN_TIER_medium', 'PLAN_TIER_starter',\n",
      "       'PLAN_TIER_tiny', 'INDUSTRY_Accountant', 'INDUSTRY_Appliances',\n",
      "       'INDUSTRY_Audio & TV', 'INDUSTRY_Automotive',\n",
      "       'INDUSTRY_Business Services', 'INDUSTRY_Carpet Cleaning',\n",
      "       'INDUSTRY_Carpet Repair', 'INDUSTRY_Electrical', 'INDUSTRY_Flooring',\n",
      "       'INDUSTRY_General Contractor', 'INDUSTRY_Handyman',\n",
      "       'INDUSTRY_Heating & Air Conditioning', 'INDUSTRY_Home Cleaning',\n",
      "       'INDUSTRY_Home Inspection', 'INDUSTRY_Interior & Surface Cleaning',\n",
      "       'INDUSTRY_Junk Removal', 'INDUSTRY_Landscaping & Lawn',\n",
      "       'INDUSTRY_Locksmith', 'INDUSTRY_Moving', 'INDUSTRY_Painting',\n",
      "       'INDUSTRY_Pest Control', 'INDUSTRY_Plumbing', 'INDUSTRY_Restoration',\n",
      "       'INDUSTRY_Roof & Attic', 'INDUSTRY_Security', 'INDUSTRY_Smart Home',\n",
      "       'INDUSTRY_Snow Removal', 'INDUSTRY_Transportation',\n",
      "       'INDUSTRY_Water Treatment', 'INDUSTRY_Wildlife Control',\n",
      "       'INDUSTRY_Window & Exterior Cleaning', 'INDUSTRY_Windows',\n",
      "       'INDUSTRY_missing', 'STAGENAME_PRODUCT_Closed Lost_CC Attach:',\n",
      "       'STAGENAME_PRODUCT_Closed Lost_Instapay Attach:',\n",
      "       'STAGENAME_PRODUCT_Coaching Attended_CC Usage: CC Attach: Instapay Attach:',\n",
      "       'STAGENAME_PRODUCT_Committed_CC Attach:',\n",
      "       'STAGENAME_PRODUCT_Committed_Instapay Attach:',\n",
      "       'STAGENAME_PRODUCT_not called'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# train, test, val = get_dataset()\n",
    "# print(train.head())\n",
    "# print(train.columns)\n",
    "# df = pd.read_csv('../cc_attach_project.csv',index_col=0, nrows=20000)\n",
    "# df.columns\n",
    "# test.to_csv('test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_to_s3(fobj, bucket, key):\n",
    "    return boto3.Session(region_name=my_region).resource('s3').Bucket(bucket).Object(key).upload_file(fobj)\n",
    "\n",
    "def upload_to_s3(partition_name, partition):\n",
    "#     num_partition = 4                                 # partition file into 5 parts\n",
    "#     partitions = np.array_split(partition, num_partition)\n",
    "    filename = \"{}.csv\".format(partition_name)\n",
    "    partition.to_csv(filename, header=False, index=False)\n",
    "    key = \"{}/{}/{}\".format(prefix,partition_name,filename)\n",
    "    url = 's3n://{}/{}'.format(bucket, key)\n",
    "    print('Writing to {}'.format(url))\n",
    "    write_to_s3(filename, bucket, key)\n",
    "    print('Done writing to {}'.format(url))\n",
    "\n",
    "def download_from_s3(partition_name, number, filename):\n",
    "    key = \"{}/{}/{}\".format(prefix,partition_name, number)\n",
    "    url = 's3n://{}/{}'.format(bucket, key)\n",
    "    print('Reading from {}'.format(url))\n",
    "    s3 = boto3.resource('s3', region_name = my_region)\n",
    "    s3.Bucket(bucket).download_file(key, filename)\n",
    "    try:\n",
    "        s3.Bucket(bucket).download_file(key, 'mnist.local.test')\n",
    "    except botocore.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == \"404\":\n",
    "            print('The object does not exist at {}.'.format(url))\n",
    "        else:\n",
    "            raise        \n",
    "\n",
    "def upload_data():\n",
    "    train, test, val = get_dataset()\n",
    "    partitions = [(FILE_TRAIN, train), (FILE_VALIDATION, val), (FILE_TEST, test)]\n",
    "    for partition_name, partition in partitions:\n",
    "        print('{}: {}'.format(partition_name, partition.shape))\n",
    "        upload_to_s3(partition_name, partition)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n",
      "(1205612, 172)\n",
      "(819816, 172) (180842, 172) (204954, 172)\n",
      "train: (819816, 172)\n",
      "Writing to s3n://hcp-ml-project-tune/xgboost/train/train.csv\n",
      "Done writing to s3n://hcp-ml-project-tune/xgboost/train/train.csv\n",
      "validation: (204954, 172)\n",
      "Writing to s3n://hcp-ml-project-tune/xgboost/validation/validation.csv\n",
      "Done writing to s3n://hcp-ml-project-tune/xgboost/validation/validation.csv\n",
      "test: (180842, 172)\n",
      "Writing to s3n://hcp-ml-project-tune/xgboost/test/test.csv\n",
      "Done writing to s3n://hcp-ml-project-tune/xgboost/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "upload_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

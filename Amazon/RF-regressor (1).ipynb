{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "# import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "# from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "# from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.api.types import CategoricalDtype    \n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.externals import joblib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df = pd.read_csv('../cc_attach_project.csv',index_col=0, nrows=50000)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "to_drop = ['ENROLLMENT_DATE', 'DATE']\n",
    "df.drop(to_drop, inplace=True, axis=1)\n",
    "# df['ENROLLMENT_DATE'] = pd.to_datetime(df['ENROLLMENT_DATE'])\n",
    "# df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df['STAGENAME_PRODUCT'] = df['STAGENAME_PRODUCT'].fillna('not called')\n",
    "df['INDUSTRY'] = df['INDUSTRY'].fillna('missing')\n",
    "df['CASH_PERC'] = df['CASH_PERC'].fillna(0.0)  \n",
    "df['CHECK_PERC'] = df['CHECK_PERC'].fillna(0.0)\n",
    "df['OTHER_PERC'] = df['OTHER_PERC'].fillna(0.0)\n",
    "df['ACH_PERC'] = df['ACH_PERC'].fillna(0.0)\n",
    "df['CC_PERC'] = df['CC_PERC'].fillna(0.0)\n",
    "df['BILLING_PLAN_ID'] = df['BILLING_PLAN_ID'].astype('int64')\n",
    "cat_dtype = CategoricalDtype(categories=(df['PLAN_TIER'].unique()), ordered=True)\n",
    "df['PLAN_TIER'] = df['PLAN_TIER'].astype(cat_dtype) #small > medium?\n",
    "df['INDUSTRY'] = df['INDUSTRY'].astype('category')\n",
    "df['ORGSIZE'] = df['ORGSIZE'].abs()\n",
    "df['ORGSIZE'].replace(0,1, inplace=True) #should I do this?\n",
    "\n",
    "\n",
    "#convert to all floats\n",
    "# df = df.apply(pd.to_numeric, errors='ignore', downcast='float')\n",
    "\n",
    "# df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df:\n",
    "#     if df[column].dtype == np.float32 or df[column].dtype == np.int64:\n",
    "#         df[column] = df[column].astype('float64')\n",
    "# print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 98)\n"
     ]
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42500, 97) (7500, 97) (42500,) (7500,)\n"
     ]
    }
   ],
   "source": [
    "y = df['WILL_ATTACH_IN_60']\n",
    "X = df.drop('WILL_ATTACH_IN_60', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=123, \n",
    "                                                    stratify=y)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9977333333333334\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 5. Declare data preprocessing steps\n",
    "# pipeline = make_pipeline(preprocessing.StandardScaler(), \n",
    "#                          RandomForestClassifier(n_estimators=100, warm_start=True))\n",
    "# 6. Declare hyperparameters to tune\n",
    "# hyperparameters = { 'randomforestclassifier__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "#                   'randomforestclassifier__max_depth': [None, 5, 3, 1]}\n",
    " \n",
    "# 7. Tune model using cross-validation pipeline\n",
    "# clf = GridSearchCV(pipeline, hyperparameters, cv=10, refit=True,return_train_score=True)\n",
    "clf = RandomForestClassifier(n_estimators=200, max_depth=None, max_features='sqrt', n_jobs = -1, oob_score = True,\n",
    "                              random_state=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test,y_test))\n",
    "\n",
    "# print(clf.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_trains, y_trains = np.array_split(X_train, indices_or_sections=20), np.array_split(y_train, indices_or_sections=20)    \n",
    "\n",
    "# for X_train_section, y_train_section in zip(X_trains, y_trains):\n",
    "#     print(\"TRAIN:\", X_train_section.shape, \"TEST:\", y_train_section.shape)\n",
    "#     clf.fit(X_train_section, y_train_section)\n",
    "# print(clf.score(X_test,y_test))\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomForestClassifier' object has no attribute 'best_params_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1f53e530bf83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(clf.feature_importances_)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomForestClassifier' object has no attribute 'best_params_'"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "# print(clf.feature_importances_)\n",
    "results = clf.cv_results_\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_)\n",
    "print(results['mean_train_score'])\n",
    "print(results['mean_test_score'])\n",
    "# joblib.dump(clf, 'rf_regressor.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
